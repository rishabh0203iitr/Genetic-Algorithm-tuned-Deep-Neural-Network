{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import GA\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducing the number of rows\n",
    "\n",
    "a=x_train[y_train==0][:500]\n",
    "a1=x_test[y_test==0][:100]\n",
    "\n",
    "i=1\n",
    "while i<10:\n",
    "    a=np.append(a,x_train[y_train==i][:500],axis=0)\n",
    "    a1=np.append(a1,x_test[y_test==i][:100],axis=0)\n",
    "    i=i+1\n",
    "    \n",
    "b=np.array([np.full((500,),0),np.full((500,),1),np.full((500,),2),np.full((500,),3),np.full((500,),4),np.full((500,),5),np.full((500,),6),np.full((500,),7),np.full((500,),8),np.full((500,),9)])\n",
    "b=b.reshape((5000,))\n",
    "\n",
    "b1=np.array([np.full((100,),0),np.full((100,),1),np.full((100,),2),np.full((100,),3),np.full((100,),4),np.full((100,),5),np.full((100,),6),np.full((100,),7),np.full((100,),8),np.full((100,),9)])\n",
    "b1=b1.reshape((1000,))\n",
    "\n",
    "x_,y_=a,b\n",
    "x1_,y1_=a1,b1\n",
    "\n",
    "s = np.arange(x_.shape[0])\n",
    "s1 = np.arange(x1_.shape[0])\n",
    "np.random.shuffle(s)\n",
    "np.random.shuffle(s1)\n",
    "x_train=x_[s]\n",
    "y_train=y_[s]\n",
    "x_test=x1_[s1]\n",
    "y_test=y1_[s1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape((x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
    "x_test=x_test.reshape((x_test.shape[0],x_test.shape[1]*x_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = StandardScaler().fit_transform(x_train)\n",
    "X_test = StandardScaler().fit_transform(x_test)\n",
    "#print(standardized_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=200).fit(pd.DataFrame(X_train))\n",
    "pca_2d = pca.transform(pd.DataFrame(X_train))\n",
    "X_train = np.array(pca_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN\n",
    "\n",
    "def sigmoid(inpt):\n",
    "    return 1.0 / (1.0 + np.exp(-1 * inpt))\n",
    "\n",
    "def relu(inpt):\n",
    "    result = inpt\n",
    "    result[inpt < 0] = 0\n",
    "    return result\n",
    "\n",
    "def predict_outputs(weights_mat, data_inputs, data_outputs, activation=\"relu\"):\n",
    "    predictions = np.zeros(shape=(data_inputs.shape[0]))\n",
    "    for sample_idx in range(data_inputs.shape[0]):\n",
    "        r1 = data_inputs[sample_idx, :]\n",
    "        for curr_weights in weights_mat:\n",
    "            r1 = np.matmul(r1,curr_weights)\n",
    "            if activation == \"relu\":\n",
    "                r1 = relu(r1)\n",
    "            elif activation == \"sigmoid\":\n",
    "                r1 = sigmoid(r1)\n",
    "        predicted_label = np.where(r1 == np.max(r1))[0][0]\n",
    "        predictions[sample_idx] = predicted_label\n",
    "    correct_predictions = np.where(predictions == data_outputs)[0].size\n",
    "    accuracy = (correct_predictions / data_outputs.size) * 100\n",
    "    return accuracy, predictions\n",
    "\n",
    "def fitness(weights_mat, data_inputs, data_outputs, activation=\"relu\"):\n",
    "    accuracy = np.empty(shape=(weights_mat.shape[0]))\n",
    "    for sol_idx in range(weights_mat.shape[0]):\n",
    "        curr_sol_mat = weights_mat[sol_idx, :]\n",
    "        accuracy[sol_idx] , abc = predict_outputs(curr_sol_mat, data_inputs, data_outputs, activation=\"relu\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GA\n",
    "import random\n",
    "\n",
    "# Converting each solution from matrix to vector.\n",
    "def mat_to_vector(mat_pop_weights):\n",
    "    pop_weights_vector = []\n",
    "    for sol_idx in range(mat_pop_weights.shape[0]):\n",
    "        curr_vector = []\n",
    "        for layer_idx in range(mat_pop_weights.shape[1]):\n",
    "            vector_weights = np.reshape(mat_pop_weights[sol_idx, layer_idx], newshape=(mat_pop_weights[sol_idx, layer_idx].size))\n",
    "            curr_vector.extend(vector_weights)\n",
    "        pop_weights_vector.append(curr_vector)\n",
    "    return np.array(pop_weights_vector)\n",
    "\n",
    "# Converting each solution from vector to matrix.\n",
    "def vector_to_mat(vector_pop_weights, mat_pop_weights):\n",
    "    mat_weights = []\n",
    "    for sol_idx in range(mat_pop_weights.shape[0]):\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for layer_idx in range(mat_pop_weights.shape[1]):\n",
    "            end = end + mat_pop_weights[sol_idx, layer_idx].size\n",
    "            curr_vector = vector_pop_weights[sol_idx, start:end]\n",
    "            mat_layer_weights = np.reshape(curr_vector, newshape=(mat_pop_weights[sol_idx, layer_idx].shape))\n",
    "            mat_weights.append(mat_layer_weights)\n",
    "            start = end\n",
    "    return np.reshape(mat_weights, newshape=mat_pop_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the initial population.\n",
    "pop_size=20\n",
    "n_gen=1000\n",
    "initial_pop_weights = []\n",
    "for curr_sol in range(pop_size):\n",
    "    \n",
    "    HL1_neurons = 150\n",
    "    input_HL1_weights = np.random.uniform(low=-0.1, high=0.1, \n",
    "\n",
    "                                             size=(X_train.shape[1], HL1_neurons))\n",
    "\n",
    "    HL2_neurons = 60\n",
    "    HL1_HL2_weights = np.random.uniform(low=-0.1, high=0.1, \n",
    "\n",
    "                                             size=(HL1_neurons, HL2_neurons))\n",
    "\n",
    "    output_neurons = 10\n",
    "    HL2_output_weights = np.random.uniform(low=-0.1, high=0.1, \n",
    "\n",
    "                                              size=(HL2_neurons, output_neurons))\n",
    "\n",
    "    initial_pop_weights.append(np.array([input_HL1_weights, \n",
    "\n",
    "                                                HL1_HL2_weights, \n",
    "\n",
    "                                                HL2_output_weights]))\n",
    "pop_weights_mat = np.array(initial_pop_weights)\n",
    "pop_weights_vector = mat_to_vector(pop_weights_mat)\n",
    "\n",
    "f=fitness(pop_weights_mat,X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=np.array(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_gen):\n",
    "    \n",
    "    \n",
    "    parents=GA.tournament_selection(pop_weights_vector,f) \n",
    "    f1=f\n",
    "    \n",
    "    child=np.full((parents.shape),np.nan)\n",
    "    \n",
    "    #CROSSOVERS\n",
    "    child=GA.sbx_real(parents,1,10)\n",
    "\n",
    "    #MUTATIONS\n",
    "    child=GA.mut_poly(child,50,-0.1,0.1,0.05)\n",
    "    child=child.astype('float')\n",
    "    #fitness\n",
    "    f=fitness(np.array(vector_to_mat(child,pop_weights_mat)),X_train,y_train)\n",
    "    \n",
    "    con=np.concatenate((child,f.reshape((f.shape[0]),1)),axis=1)\n",
    "    con=con[con[:,-1].argsort()][::-1]\n",
    "    child=con[:,:-1]\n",
    "    \n",
    "    child[10:,:]=parents[:10,:]\n",
    "    f[10:]=f1[:10]\n",
    "    \n",
    "    pop_weights_vector=child\n",
    "    \n",
    "    print(\"gen:\",i+1, \"child\",child)\n",
    "    print(\"fitness:\",f,\"Best Fitness\",max(f))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
